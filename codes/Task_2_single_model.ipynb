{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10399957,
          "sourceType": "datasetVersion",
          "datasetId": 6443852
        },
        {
          "sourceId": 10401145,
          "sourceType": "datasetVersion",
          "datasetId": 6444772
        },
        {
          "sourceId": 10419045,
          "sourceType": "datasetVersion",
          "datasetId": 6457498
        }
      ],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Setting up the enviroment"
      ],
      "metadata": {
        "id": "mh7dFCORL0eR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tabjular Data Analysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Utility\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "1dWgrRIOL1fp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:30.839130Z",
          "iopub.execute_input": "2025-01-10T08:29:30.839502Z",
          "iopub.status.idle": "2025-01-10T08:29:30.844230Z",
          "shell.execute_reply.started": "2025-01-10T08:29:30.839468Z",
          "shell.execute_reply": "2025-01-10T08:29:30.843161Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Load the dataset"
      ],
      "metadata": {
        "id": "k18aD2SaL40a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_df = pd.read_csv(\"/content/fake_news_classification_mal_train(3).csv\")\n",
        "all_df.head(3)"
      ],
      "metadata": {
        "id": "5vymL2NfL53g",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:30.845457Z",
          "iopub.execute_input": "2025-01-10T08:29:30.845690Z",
          "iopub.status.idle": "2025-01-10T08:29:30.883006Z",
          "shell.execute_reply.started": "2025-01-10T08:29:30.845669Z",
          "shell.execute_reply": "2025-01-10T08:29:30.882398Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to drop\n",
        "#columns_to_drop = ['Unnamed: 0']\n",
        "\n",
        "# Drop the columns\n",
        "#train_df = train_df.drop(columns=columns_to_drop)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:30.884046Z",
          "iopub.execute_input": "2025-01-10T08:29:30.884256Z",
          "iopub.status.idle": "2025-01-10T08:29:30.887289Z",
          "shell.execute_reply.started": "2025-01-10T08:29:30.884238Z",
          "shell.execute_reply": "2025-01-10T08:29:30.886507Z"
        },
        "id": "d_bO5te6EAU0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "6A5tLOEN-n8u",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:30.888431Z",
          "iopub.execute_input": "2025-01-10T08:29:30.888694Z",
          "iopub.status.idle": "2025-01-10T08:29:30.902523Z",
          "shell.execute_reply.started": "2025-01-10T08:29:30.888672Z",
          "shell.execute_reply": "2025-01-10T08:29:30.901647Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train, validation\n",
        "train_df, val_df = train_test_split(all_df, test_size=0.2, stratify=all_df[\"Label\"], random_state=42)"
      ],
      "metadata": {
        "id": "T-wpvNnK-t7B",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:30.903241Z",
          "iopub.execute_input": "2025-01-10T08:29:30.903519Z",
          "iopub.status.idle": "2025-01-10T08:29:30.921454Z",
          "shell.execute_reply.started": "2025-01-10T08:29:30.903485Z",
          "shell.execute_reply": "2025-01-10T08:29:30.920716Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(\"/content/fake_news_classification_mal_test.xlsx - Sheet1.csv\")\n",
        "test_df.head(3)"
      ],
      "metadata": {
        "id": "2E_VKeHrOV6G",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:30.922219Z",
          "iopub.execute_input": "2025-01-10T08:29:30.922504Z",
          "iopub.status.idle": "2025-01-10T08:29:30.941761Z",
          "shell.execute_reply.started": "2025-01-10T08:29:30.922483Z",
          "shell.execute_reply": "2025-01-10T08:29:30.940991Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_VAR = \"News\"\n",
        "LABEL_VAR = \"Label\""
      ],
      "metadata": {
        "id": "vBV05Fncp8BN",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:30.943675Z",
          "iopub.execute_input": "2025-01-10T08:29:30.943865Z",
          "iopub.status.idle": "2025-01-10T08:29:30.952246Z",
          "shell.execute_reply.started": "2025-01-10T08:29:30.943848Z",
          "shell.execute_reply": "2025-01-10T08:29:30.951560Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Labels are not numerical. Let's make them numerical."
      ],
      "metadata": {
        "id": "pWPhww7yS-IM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map text labels to numerical values\n",
        "label_mapping = {label: idx for idx, label in enumerate(train_df[LABEL_VAR].unique())}\n",
        "train_df[LABEL_VAR] = train_df[LABEL_VAR].map(label_mapping)  # Change as necessary\n",
        "val_df[LABEL_VAR] = val_df[LABEL_VAR].map(label_mapping)  # Change as necessary"
      ],
      "metadata": {
        "id": "-OFVXk3HPXj2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:30.953244Z",
          "iopub.execute_input": "2025-01-10T08:29:30.953544Z",
          "iopub.status.idle": "2025-01-10T08:29:30.969142Z",
          "shell.execute_reply.started": "2025-01-10T08:29:30.953505Z",
          "shell.execute_reply": "2025-01-10T08:29:30.968412Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "DiD1U4XjudBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Things"
      ],
      "metadata": {
        "id": "e47rxAVBOFx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoModel, AutoTokenizer, AutoProcessor\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "6rnkckw3nPMn",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:30.969851Z",
          "iopub.execute_input": "2025-01-10T08:29:30.970102Z",
          "iopub.status.idle": "2025-01-10T08:29:30.984373Z",
          "shell.execute_reply.started": "2025-01-10T08:29:30.970083Z",
          "shell.execute_reply": "2025-01-10T08:29:30.983539Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "XZ9DGFwlncqP",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:30.985179Z",
          "iopub.execute_input": "2025-01-10T08:29:30.985502Z",
          "iopub.status.idle": "2025-01-10T08:29:30.999087Z",
          "shell.execute_reply.started": "2025-01-10T08:29:30.985471Z",
          "shell.execute_reply": "2025-01-10T08:29:30.998320Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "torch.manual_seed(seed)"
      ],
      "metadata": {
        "id": "K10J2skvHanJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:31.011310Z",
          "iopub.execute_input": "2025-01-10T08:29:31.011555Z",
          "iopub.status.idle": "2025-01-10T08:29:31.017775Z",
          "shell.execute_reply.started": "2025-01-10T08:29:31.011535Z",
          "shell.execute_reply": "2025-01-10T08:29:31.016886Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "model_name = \"l3cube-pune/malayalam-topic-all-doc\"\n",
        "batch_size = 16\n",
        "max_length = 512"
      ],
      "metadata": {
        "id": "TzwK6-Jgn9OX",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:31.018783Z",
          "iopub.execute_input": "2025-01-10T08:29:31.018981Z",
          "iopub.status.idle": "2025-01-10T08:29:31.029732Z",
          "shell.execute_reply.started": "2025-01-10T08:29:31.018963Z",
          "shell.execute_reply": "2025-01-10T08:29:31.029004Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Tokenizer and Model\n",
        "text_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "text_model = AutoModel.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "id": "7BPWR_jaoUPG",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:31.031133Z",
          "iopub.execute_input": "2025-01-10T08:29:31.031391Z",
          "iopub.status.idle": "2025-01-10T08:29:31.753772Z",
          "shell.execute_reply.started": "2025-01-10T08:29:31.031365Z",
          "shell.execute_reply": "2025-01-10T08:29:31.753088Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        transcription = self.df.iloc[idx][TEXT_VAR]\n",
        "        transcription = transcription if isinstance(transcription, str) else \"\"\n",
        "        inputs = self.tokenizer(\n",
        "            transcription, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\"\n",
        "        )\n",
        "        return inputs, self.df.iloc[idx][LABEL_VAR]"
      ],
      "metadata": {
        "id": "NUv10RXNog5F",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:31.755198Z",
          "iopub.execute_input": "2025-01-10T08:29:31.755514Z",
          "iopub.status.idle": "2025-01-10T08:29:31.760238Z",
          "shell.execute_reply.started": "2025-01-10T08:29:31.755483Z",
          "shell.execute_reply": "2025-01-10T08:29:31.759437Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collect Embeddings"
      ],
      "metadata": {
        "id": "SvDAb6ndrsB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_embeddings(df, save_path, model, tokenizer):\n",
        "    if os.path.exists(save_path):\n",
        "        print(f\"Embeddings already exist at {save_path}\")\n",
        "        return torch.load(save_path)\n",
        "\n",
        "    embeddings = {}\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx, row in tqdm(df.iterrows(), desc=\"Extracting text embeddings\", total=len(df)):\n",
        "            transcription = row[TEXT_VAR]\n",
        "            transcription = transcription if isinstance(transcription, str) else \"\"\n",
        "\n",
        "            # Tokenize the text\n",
        "            inputs = tokenizer(\n",
        "                transcription, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\"\n",
        "            )\n",
        "            inputs = {key: value.to(device) for key, value in inputs.items()}  # Move inputs to GPU/CPU\n",
        "\n",
        "            # Extract embeddings\n",
        "            outputs = model(**inputs)\n",
        "            cls_embedding = outputs.last_hidden_state[:, 0, :]  # [CLS] token embeddings\n",
        "            embeddings[idx] = cls_embedding.cpu()  # Use the index as the key\n",
        "\n",
        "    torch.save(embeddings, save_path)\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "FHrgied3qYUE",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:31.761242Z",
          "iopub.execute_input": "2025-01-10T08:29:31.761566Z",
          "iopub.status.idle": "2025-01-10T08:29:31.778787Z",
          "shell.execute_reply.started": "2025-01-10T08:29:31.761537Z",
          "shell.execute_reply": "2025-01-10T08:29:31.778067Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_embeddings = extract_text_embeddings(\n",
        "    train_df, \"train_text_embeddings.pt\", text_model, text_tokenizer\n",
        ")\n",
        "val_text_embeddings = extract_text_embeddings(\n",
        "    val_df, \"val_text_embeddings.pt\", text_model, text_tokenizer\n",
        ")\n",
        "test_text_embeddings = extract_text_embeddings(\n",
        "    test_df, \"test_text_embeddings.pt\", text_model, text_tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "H3J08p08qdnl",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:31.779489Z",
          "iopub.execute_input": "2025-01-10T08:29:31.779746Z",
          "iopub.status.idle": "2025-01-10T08:29:31.874654Z",
          "shell.execute_reply.started": "2025-01-10T08:29:31.779718Z",
          "shell.execute_reply": "2025-01-10T08:29:31.873983Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Embeddings"
      ],
      "metadata": {
        "id": "LKT81NDSse1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_embeddings(embedding_path):\n",
        "    if os.path.exists(embedding_path):\n",
        "        print(f\"Loading embeddings from {embedding_path}\")\n",
        "        return torch.load(embedding_path)\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Embeddings file not found at {embedding_path}\")"
      ],
      "metadata": {
        "id": "f19wvaWMsktS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:31.875434Z",
          "iopub.execute_input": "2025-01-10T08:29:31.875624Z",
          "iopub.status.idle": "2025-01-10T08:29:31.879206Z",
          "shell.execute_reply.started": "2025-01-10T08:29:31.875607Z",
          "shell.execute_reply": "2025-01-10T08:29:31.878485Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_embeddings = load_embeddings(\"/content/train_text_embeddings.pt\")\n",
        "val_text_embeddings = load_embeddings(\"/content/val_text_embeddings.pt\")\n",
        "test_text_embeddings = load_embeddings(\"/content/test_text_embeddings.pt\")"
      ],
      "metadata": {
        "id": "OUb9t8sjrUCM",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:31.879989Z",
          "iopub.execute_input": "2025-01-10T08:29:31.880194Z",
          "iopub.status.idle": "2025-01-10T08:29:31.977858Z",
          "shell.execute_reply.started": "2025-01-10T08:29:31.880165Z",
          "shell.execute_reply": "2025-01-10T08:29:31.977092Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "Pvc6Dm5kshIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "z0Tb_r_irT27",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:31.980065Z",
          "iopub.execute_input": "2025-01-10T08:29:31.980282Z",
          "iopub.status.idle": "2025-01-10T08:29:31.983646Z",
          "shell.execute_reply.started": "2025-01-10T08:29:31.980262Z",
          "shell.execute_reply": "2025-01-10T08:29:31.982826Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_text_embeddings(text_embeddings, df, LABEL_VAR, has_labels=True):\n",
        "    combined_embeddings = []\n",
        "    labels = [] if has_labels else None\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        # Ensure the index exists in the text embeddings\n",
        "        if idx in text_embeddings:\n",
        "            text_embedding = text_embeddings[idx].squeeze()  # Squeeze to remove unnecessary dimensions\n",
        "\n",
        "            # Add the text embedding to the list\n",
        "            combined_embeddings.append(text_embedding)\n",
        "\n",
        "            if has_labels:\n",
        "                labels.append(row[LABEL_VAR])  # Get the label from the DataFrame\n",
        "\n",
        "    if has_labels:\n",
        "        return torch.stack(combined_embeddings), torch.tensor(labels)\n",
        "    else:\n",
        "        return torch.stack(combined_embeddings)"
      ],
      "metadata": {
        "id": "zyDdzX-AtsbZ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:31.984891Z",
          "iopub.execute_input": "2025-01-10T08:29:31.985121Z",
          "iopub.status.idle": "2025-01-10T08:29:31.998868Z",
          "shell.execute_reply.started": "2025-01-10T08:29:31.985102Z",
          "shell.execute_reply": "2025-01-10T08:29:31.998084Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = prepare_text_embeddings(train_text_embeddings, train_df, LABEL_VAR)\n",
        "X_val, y_val = prepare_text_embeddings(val_text_embeddings, val_df, LABEL_VAR)\n",
        "X_test = prepare_text_embeddings(test_text_embeddings, test_df, LABEL_VAR, has_labels=False)\n",
        "\n",
        "print(f\"Training data shape: {X_train.shape}, Labels: {y_train.shape}\")\n",
        "print(f\"Validation data shape: {X_val.shape}, Labels: {y_val.shape}\")\n",
        "print(f\"Test data shape: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "lemZ0ItCtvqx",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:31.999489Z",
          "iopub.execute_input": "2025-01-10T08:29:31.999674Z",
          "iopub.status.idle": "2025-01-10T08:29:32.117729Z",
          "shell.execute_reply.started": "2025-01-10T08:29:31.999657Z",
          "shell.execute_reply": "2025-01-10T08:29:32.116888Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "def new_balance_classes(X, y):\n",
        "\n",
        "  # Load embeddings from .pt file\n",
        "#     embeddings = torch.load(embeddings_path)\n",
        "\n",
        "  # Count occurrences of each class\n",
        "  train_df=pd.DataFrame({\"Label\":y})\n",
        "  class_counts = Counter(train_df['Label'])\n",
        "\n",
        "\n",
        "\n",
        "  # Find the maximum count\n",
        "  max_count = max(class_counts.values())\n",
        "\n",
        "  # Create a new list for balanced data\n",
        "  label_lst = []\n",
        "  embedding_lst=[]\n",
        "\n",
        "\n",
        "  for idx, row in train_df.iterrows():\n",
        "      label = row[LABEL_VAR]\n",
        "      embedding = X[idx]  # Assuming embeddings are in the same order as DataFrame\n",
        "\n",
        "      # Add original sample\n",
        "      embedding_lst.append(embedding)  # Duplicate sample\n",
        "      label_lst.append(label)\n",
        "\n",
        "\n",
        "\n",
        "      # Duplicate samples for minority classes\n",
        "      duplicates_needed = int( (max_count - class_counts[label]) / class_counts[label])\n",
        "      for _ in range(duplicates_needed):\n",
        "          embedding_lst.append(embedding)  # Duplicate sample\n",
        "          label_lst.append(label)\n",
        "\n",
        "\n",
        "  return torch.stack(embedding_lst), np.array(label_lst)\n",
        "\n",
        "\n",
        "# # train_df.head()\n",
        "X_train,y_train=new_balance_classes(X_train,y_train)\n",
        "\n",
        "X_train = torch.tensor(X_train)\n",
        "y_train = torch.tensor(y_train)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:32.118526Z",
          "iopub.execute_input": "2025-01-10T08:29:32.118743Z",
          "iopub.status.idle": "2025-01-10T08:29:32.188179Z",
          "shell.execute_reply.started": "2025-01-10T08:29:32.118723Z",
          "shell.execute_reply": "2025-01-10T08:29:32.187411Z"
        },
        "id": "2iJ2-zefEAU7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MLP model\n",
        "class MLPModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_p=0.35):\n",
        "        \"\"\"\n",
        "        Initialize the MLP model.\n",
        "        Args:\n",
        "            input_dim (int): Dimension of the input features.\n",
        "            hidden_dim (list of int): List of dimensions for hidden layers.\n",
        "            output_dim (int): Dimension of the output layer.\n",
        "            dropout_p (float): Dropout probability.\n",
        "        \"\"\"\n",
        "        super(MLPModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(p=dropout_p)\n",
        "        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
        "        self.dropout2 = nn.Dropout(p=dropout_p)\n",
        "        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kG2eSLEzuDQJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:29:32.188866Z",
          "iopub.execute_input": "2025-01-10T08:29:32.189068Z",
          "iopub.status.idle": "2025-01-10T08:29:32.194645Z",
          "shell.execute_reply.started": "2025-01-10T08:29:32.189050Z",
          "shell.execute_reply": "2025-01-10T08:29:32.193679Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "input_dim = X_train.shape[1]\n",
        "num_classes = len(train_df[LABEL_VAR].unique())\n",
        "hidden_dim = [768, 512]  # Increased hidden layer dimensions\n",
        "output_dim = num_classes\n",
        "batch_size = 16  # Smaller batch size\n",
        "learning_rate = 0.0001  # Increased learning rate\n",
        "dropout_p = 0.35"
      ],
      "metadata": {
        "id": "mT_Yy49YuGXK",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:48:14.734822Z",
          "iopub.execute_input": "2025-01-10T08:48:14.735145Z",
          "iopub.status.idle": "2025-01-10T08:48:14.740088Z",
          "shell.execute_reply.started": "2025-01-10T08:48:14.735116Z",
          "shell.execute_reply": "2025-01-10T08:48:14.739028Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data loaders\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "test_dataset = TensorDataset(X_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size)"
      ],
      "metadata": {
        "id": "nkOVzPn1uLyp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:48:15.314918Z",
          "iopub.execute_input": "2025-01-10T08:48:15.315187Z",
          "iopub.status.idle": "2025-01-10T08:48:15.319710Z",
          "shell.execute_reply.started": "2025-01-10T08:48:15.315165Z",
          "shell.execute_reply": "2025-01-10T08:48:15.318709Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, loss function, and optimizer\n",
        "model = MLPModel(input_dim, hidden_dim, output_dim, dropout_p).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "zeI8r1aTuOWM",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:48:15.895977Z",
          "iopub.execute_input": "2025-01-10T08:48:15.896253Z",
          "iopub.status.idle": "2025-01-10T08:48:15.910220Z",
          "shell.execute_reply.started": "2025-01-10T08:48:15.896231Z",
          "shell.execute_reply": "2025-01-10T08:48:15.909360Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate metrics\n",
        "def calculate_metrics(preds, labels):\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"macro\")\n",
        "    return accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "bYP39h-txZOp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:48:18.364896Z",
          "iopub.execute_input": "2025-01-10T08:48:18.365180Z",
          "iopub.status.idle": "2025-01-10T08:48:18.369231Z",
          "shell.execute_reply.started": "2025-01-10T08:48:18.365158Z",
          "shell.execute_reply": "2025-01-10T08:48:18.368235Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = train_df['News'].str.len().max()\n",
        "print(f\"Maximum text length: {max_length}\")"
      ],
      "metadata": {
        "id": "ZVaI4xlacFX-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:48:18.908788Z",
          "iopub.execute_input": "2025-01-10T08:48:18.909031Z",
          "iopub.status.idle": "2025-01-10T08:48:18.915241Z",
          "shell.execute_reply.started": "2025-01-10T08:48:18.909007Z",
          "shell.execute_reply": "2025-01-10T08:48:18.914575Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = val_df['News'].str.len().mean()\n",
        "print(f\"Maximum text length: {max_length}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:48:19.469652Z",
          "iopub.execute_input": "2025-01-10T08:48:19.469902Z",
          "iopub.status.idle": "2025-01-10T08:48:19.475929Z",
          "shell.execute_reply.started": "2025-01-10T08:48:19.469881Z",
          "shell.execute_reply": "2025-01-10T08:48:19.474899Z"
        },
        "id": "dBpbTaKUEAU8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Val"
      ],
      "metadata": {
        "id": "xCjg-mNzuZxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and save best model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "def train_and_save_best_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, save_dir):\n",
        "    best_f1 = -float('inf')\n",
        "    best_model_path = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train() # Indent this line. Start of the loop\n",
        "        train_loss = 0\n",
        "        all_train_preds, all_train_labels = [], []\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs) # Remove the squeeze function\n",
        "\n",
        "            #check if a single sample is passed in as a batch\n",
        "            if outputs.shape[0] == 1:\n",
        "                continue\n",
        "\n",
        "            # Compute loss and backpropagate\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            all_train_preds.extend(preds.cpu().tolist())\n",
        "            all_train_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "        # Calculate training metrics\n",
        "        train_accuracy, train_precision, train_recall, train_f1 = calculate_metrics(all_train_preds, all_train_labels)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        all_val_preds, all_val_labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs) # Remove the squeeze function\n",
        "                #check if a single sample is passed in as a batch\n",
        "                if outputs.shape[0] == 1:\n",
        "                    continue\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, preds = torch.max(outputs, dim=1)\n",
        "                all_val_preds.extend(preds.cpu().tolist())\n",
        "                all_val_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "        # Calculate validation metrics\n",
        "        val_accuracy, val_precision, val_recall, val_f1 = calculate_metrics(all_val_preds, all_val_labels)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss/len(train_loader):.4f}, \"\n",
        "              f\"Train Acc: {train_accuracy:.4f}, Prec: {train_precision:.4f}, Rec: {train_recall:.4f}, F1: {train_f1:.4f} | \"\n",
        "              f\"Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_accuracy:.4f}, Prec: {val_precision:.4f}, \"\n",
        "              f\"Rec: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
        "\n",
        "        # Save the model if it has the best F1 score on validation\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "            best_model_path = f\"{save_dir}/best_model_epoch_{epoch + 1}_f1_{val_f1:.4f}.pth\"\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f\"Best model saved with F1: {val_f1:.4f} at epoch {epoch + 1}\")\n",
        "\n",
        "    return best_model_path"
      ],
      "metadata": {
        "id": "1qFE7USauREx",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:48:22.227580Z",
          "iopub.execute_input": "2025-01-10T08:48:22.227867Z",
          "iopub.status.idle": "2025-01-10T08:48:22.236986Z",
          "shell.execute_reply.started": "2025-01-10T08:48:22.227844Z",
          "shell.execute_reply": "2025-01-10T08:48:22.235995Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the directory where the best model will be saved\n",
        "save_dir = \"./models\"\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "QpEjhQXkuTYq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:48:25.252181Z",
          "iopub.execute_input": "2025-01-10T08:48:25.252559Z",
          "iopub.status.idle": "2025-01-10T08:48:25.256996Z",
          "shell.execute_reply.started": "2025-01-10T08:48:25.252525Z",
          "shell.execute_reply": "2025-01-10T08:48:25.255865Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model and save the best model\n",
        "best_model_path = train_and_save_best_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=50,\n",
        "    save_dir=save_dir\n",
        ")\n",
        "\n",
        "print(f\"Best model saved at: {best_model_path}\")"
      ],
      "metadata": {
        "id": "UI2TuU_nxehv",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:49:03.981520Z",
          "iopub.execute_input": "2025-01-10T08:49:03.981792Z",
          "iopub.status.idle": "2025-01-10T08:54:24.498392Z",
          "shell.execute_reply.started": "2025-01-10T08:49:03.981771Z",
          "shell.execute_reply": "2025-01-10T08:54:24.497447Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "tQI1YtBouXDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_generate_submission(test_loader, best_model_path, submission_file_path):\n",
        "    # Load the best model with weights_only=True to avoid security warnings\n",
        "    model = MLPModel(input_dim, hidden_dim, output_dim, dropout_p).to(device)\n",
        "    model.load_state_dict(torch.load(best_model_path, weights_only=True))\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    test_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for inputs in test_loader:\n",
        "            # Ensure inputs are converted to a tensor and stacked into a batch if necessary\n",
        "            if isinstance(inputs, list):\n",
        "                # Convert each item to tensor using .detach() to avoid the user warning\n",
        "                inputs = [i.clone().detach().to(device) if isinstance(i, torch.Tensor) else torch.tensor(i).to(device) for i in inputs]\n",
        "                inputs = torch.stack(inputs)  # Stack them into a batch tensor\n",
        "            else:\n",
        "                inputs = inputs.to(device)  # If inputs is already a tensor, move it to device\n",
        "\n",
        "            outputs = model(inputs).squeeze()\n",
        "\n",
        "            # Predict binary labels\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            test_predictions.extend(preds.tolist())\n",
        "\n",
        "    # Prepare the submission DataFrame\n",
        "    submission_df = pd.DataFrame({\n",
        "        TEXT_VAR: [i for i in test_df[TEXT_VAR]],\n",
        "        'predictions': test_predictions\n",
        "    })\n",
        "\n",
        "    # Save the predictions to a CSV file\n",
        "    submission_df.to_csv(submission_file_path, index=False)\n",
        "    print(f\"Submission file saved to {submission_file_path}\")\n",
        "\n",
        "    return submission_df"
      ],
      "metadata": {
        "id": "0-tQuWKjuWVC",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:54:38.214407Z",
          "iopub.execute_input": "2025-01-10T08:54:38.214723Z",
          "iopub.status.idle": "2025-01-10T08:54:38.221107Z",
          "shell.execute_reply.started": "2025-01-10T08:54:38.214688Z",
          "shell.execute_reply": "2025-01-10T08:54:38.220081Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "submission_file_path = \"submission.csv\"\n",
        "submission_df = predict_and_generate_submission(test_loader=test_loader, best_model_path=best_model_path, submission_file_path=submission_file_path)"
      ],
      "metadata": {
        "id": "LmRfUjoxxyzA",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:54:42.548476Z",
          "iopub.execute_input": "2025-01-10T08:54:42.548761Z",
          "iopub.status.idle": "2025-01-10T08:54:42.578032Z",
          "shell.execute_reply.started": "2025-01-10T08:54:42.548738Z",
          "shell.execute_reply": "2025-01-10T08:54:42.577372Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df.head()"
      ],
      "metadata": {
        "id": "nMKXQNe6yamA",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:54:45.815502Z",
          "iopub.execute_input": "2025-01-10T08:54:45.815784Z",
          "iopub.status.idle": "2025-01-10T08:54:45.823371Z",
          "shell.execute_reply.started": "2025-01-10T08:54:45.815763Z",
          "shell.execute_reply": "2025-01-10T08:54:45.822523Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def get_error_examples(model, dataloader, data, label_mapping):\n",
        "    model.eval()\n",
        "    incorrect_examples = []\n",
        "    reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "            labels = labels.cpu().numpy()\n",
        "\n",
        "            # Collect incorrect examples\n",
        "            for idx, (pred, label) in enumerate(zip(preds, labels)):\n",
        "                if pred != label:  # Only collect incorrect ones\n",
        "                    incorrect_examples.append({\n",
        "                        \"text\": data.iloc[i * dataloader.batch_size + idx][\"News\"],\n",
        "                        \"true_label\": label,\n",
        "                        \"predicted_label\": pred\n",
        "                    })\n",
        "\n",
        "    # Randomly sample 5 incorrect examples (or fewer if less than 5 total)\n",
        "    if len(incorrect_examples) >= 5:\n",
        "        sampled_errors = random.sample(incorrect_examples, 5)\n",
        "    else:\n",
        "        sampled_errors = incorrect_examples\n",
        "\n",
        "    # Display the examples\n",
        "    for error in sampled_errors:\n",
        "        print(f\"Text: {error['text']}\")\n",
        "        print(f\"True Label: {error['true_label']} ({reverse_label_mapping[error['true_label']]})\")\n",
        "        print(f\"Predicted Label: {error['predicted_label']} ({reverse_label_mapping[error['predicted_label']]})\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "# Example call on the validation set:\n",
        "get_error_examples(model, val_loader, val_df, label_mapping)\n"
      ],
      "metadata": {
        "id": "F1xsjOcKVIlQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}